{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9838712,"sourceType":"datasetVersion","datasetId":6035411},{"sourceId":9851007,"sourceType":"datasetVersion","datasetId":6035458},{"sourceId":159542,"sourceType":"modelInstanceVersion","modelInstanceId":135638,"modelId":158370}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install cvzone ultralytics opencv-python-headless\n!pip install torch\nimport torch\nimport cvzone\nfrom ultralytics import YOLO\nimport cv2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T09:42:21.750079Z","iopub.execute_input":"2024-11-10T09:42:21.750738Z","iopub.status.idle":"2024-11-10T09:42:53.297648Z","shell.execute_reply.started":"2024-11-10T09:42:21.750688Z","shell.execute_reply":"2024-11-10T09:42:53.296652Z"}},"outputs":[{"name":"stdout","text":"Collecting cvzone\n  Downloading cvzone-1.6.1.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ultralytics\n  Downloading ultralytics-8.3.28-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (4.10.0.84)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from cvzone) (4.10.0.84)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from cvzone) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.11-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.3.28-py3-none-any.whl (881 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.2/881.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.11-py3-none-any.whl (26 kB)\nBuilding wheels for collected packages: cvzone\n  Building wheel for cvzone (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cvzone: filename=cvzone-1.6.1-py3-none-any.whl size=26297 sha256=62e96f01b6ce41cc652346b4afe3bf8b51686b0b3b992de54a63ad71cd7821b9\n  Stored in directory: /root/.cache/pip/wheels/2c/9f/b3/92e945ac4a71bf727a92463f38155cc5a4fa49c5010b38ec4c\nSuccessfully built cvzone\nInstalling collected packages: cvzone, ultralytics-thop, ultralytics\nSuccessfully installed cvzone-1.6.1 ultralytics-8.3.28 ultralytics-thop-2.0.11\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Test Video","metadata":{}},{"cell_type":"code","source":"VIDEO_PATH = '/kaggle/input/test-video/Test Video.mp4'\nMODEL_PATH = '/kaggle/input/yolov8n-face/pytorch/default/1/yolov8n-face.pt'\nOUTPUT_VIDEO_PATH = '/kaggle/working/Anonymized_Video.mp4'\n\n\nFRAME_WIDTH, FRAME_HEIGHT = 700, 500  \nCONFIDENCE_THRESHOLD = 0.3  \nBLUR_INTENSITY = (30, 30)  \n\ndef initialize_video_writer(output_path, width, height, fps):\n    \"\"\"Initializes a video writer to save processed video frames.\"\"\"\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    return cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef anonymize_faces(frame, face_model):\n    \"\"\"Detects faces in the frame, applies anonymization, and returns the processed frame.\"\"\"\n    detections = face_model.predict(frame, conf=CONFIDENCE_THRESHOLD, verbose=False)\n    \n    for detection in detections:\n        for box in detection.boxes:\n            x1, y1, x2, y2 = map(int, box.xyxy[0])\n            face_region = frame[y1:y2, x1:x2]\n            face_region = cv2.blur(face_region, BLUR_INTENSITY)  # Apply blurring\n            frame[y1:y2, x1:x2] = face_region \n            cvzone.cornerRect(frame, (x1, y1, x2 - x1, y2 - y1), l=9, rt=3)\n\n    return frame\n\ndef process_video(input_video_path, model_path, output_video_path):\n    \"\"\"Processes the video by detecting and anonymizing faces in each frame.\"\"\"\n    cap = cv2.VideoCapture(input_video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    \n    face_model = YOLO(model_path)\n    face_model.overrides['verbose'] = False  # Suppress model logs\n\n    out = initialize_video_writer(output_video_path, FRAME_WIDTH, FRAME_HEIGHT, fps)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break  \n\n        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT)) \n        processed_frame = anonymize_faces(frame, face_model)  \n        out.write(processed_frame)  \n\n    cap.release()\n    out.release()\n    print(f\"Anonymized video saved at {output_video_path}\")\n\nprocess_video(VIDEO_PATH, MODEL_PATH, OUTPUT_VIDEO_PATH)\n","metadata":{"_uuid":"9b515c52-d6ef-430e-ad47-ccd448bda1e2","_cell_guid":"aaa4a032-8669-4dc0-975d-54aa1289c6b4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:52:29.000727Z","iopub.execute_input":"2024-11-10T09:52:29.001101Z","iopub.status.idle":"2024-11-10T09:53:32.992541Z","shell.execute_reply.started":"2024-11-10T09:52:29.001068Z","shell.execute_reply":"2024-11-10T09:53:32.991604Z"}},"outputs":[{"name":"stdout","text":"WARNING ⚠️ /kaggle/input/yolov8n-face/pytorch/default/1/yolov8n-face.pt appears to require 'omegaconf', which is not in Ultralytics requirements.\nAutoInstall will run now for 'omegaconf' but this feature will be removed in the future.\nRecommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official Ultralytics model, i.e. 'yolo predict model=yolov8n.pt'\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['omegaconf'] not found, attempting AutoUpdate...\nCollecting omegaconf\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf) (6.0.2)\nDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n  Building wheel for antlr4-python3-runtime (setup.py): started\n  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=8e736d0a440407570e2ebfe23191814ed5c36a33a5d766ec45ad4dd3e16c9386\n  Stored in directory: /tmp/pip-ephem-wheel-cache-fuubv4o2/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\nSuccessfully built antlr4-python3-runtime\nInstalling collected packages: antlr4-python3-runtime, omegaconf\nSuccessfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 13.3s, installed 1 package: ['omegaconf']\n\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\nAnonymized video saved at /kaggle/working/Anonymized_Video.mp4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Test Video1","metadata":{}},{"cell_type":"code","source":"VIDEO_PATH = '/kaggle/input/test-video/Test Video1.mp4'\nMODEL_PATH = '/kaggle/input/yolov8n-face/pytorch/default/1/yolov8n-face.pt'\nOUTPUT_VIDEO_PATH = '/kaggle/working/Anonymized_Video1.mp4'\n\n\nFRAME_WIDTH, FRAME_HEIGHT = 700, 500  \nCONFIDENCE_THRESHOLD = 0.3  \nBLUR_INTENSITY = (30, 30)  \n\ndef initialize_video_writer(output_path, width, height, fps):\n    \"\"\"Initializes a video writer to save processed video frames.\"\"\"\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    return cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef anonymize_faces(frame, face_model):\n    \"\"\"Detects faces in the frame, applies anonymization, and returns the processed frame.\"\"\"\n    detections = face_model.predict(frame, conf=CONFIDENCE_THRESHOLD, verbose=False)\n    \n    for detection in detections:\n        for box in detection.boxes:\n            x1, y1, x2, y2 = map(int, box.xyxy[0])\n            face_region = frame[y1:y2, x1:x2]\n            face_region = cv2.blur(face_region, BLUR_INTENSITY)  # Apply blurring\n            frame[y1:y2, x1:x2] = face_region \n            cvzone.cornerRect(frame, (x1, y1, x2 - x1, y2 - y1), l=9, rt=3)\n\n    return frame\n\ndef process_video(input_video_path, model_path, output_video_path):\n    \"\"\"Processes the video by detecting and anonymizing faces in each frame.\"\"\"\n    cap = cv2.VideoCapture(input_video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    \n    face_model = YOLO(model_path)\n    face_model.overrides['verbose'] = False  # Suppress model logs\n\n    out = initialize_video_writer(output_video_path, FRAME_WIDTH, FRAME_HEIGHT, fps)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break  \n\n        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT)) \n        processed_frame = anonymize_faces(frame, face_model)  \n        out.write(processed_frame)  \n\n    cap.release()\n    out.release()\n    print(f\"Anonymized video saved at {output_video_path}\")\n\nprocess_video(VIDEO_PATH, MODEL_PATH, OUTPUT_VIDEO_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T09:55:27.974572Z","iopub.execute_input":"2024-11-10T09:55:27.975108Z","iopub.status.idle":"2024-11-10T09:55:42.528686Z","shell.execute_reply.started":"2024-11-10T09:55:27.975069Z","shell.execute_reply":"2024-11-10T09:55:42.527652Z"}},"outputs":[{"name":"stdout","text":"Anonymized video saved at /kaggle/working/Anonymized_Video1.mp4\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Test Your Video","metadata":{}},{"cell_type":"code","source":"VIDEO_PATH = 'ADD INPUT VIDEO PATH HERE' #ADD INPUT VIDEO PATH HERE\nMODEL_PATH = '/kaggle/input/yolov8n-face/pytorch/default/1/yolov8n-face.pt'\nOUTPUT_VIDEO_PATH = 'kaggle/working/ADD_OUTPUT_VIDEO_NAME_HERE.mp4' #ADD OUTPUT VIDEO NAME HERE\n\n\nFRAME_WIDTH, FRAME_HEIGHT = 700, 500  \nCONFIDENCE_THRESHOLD = 0.3  \nBLUR_INTENSITY = (30, 30)  \n\ndef initialize_video_writer(output_path, width, height, fps):\n    \"\"\"Initializes a video writer to save processed video frames.\"\"\"\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    return cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef anonymize_faces(frame, face_model):\n    \"\"\"Detects faces in the frame, applies anonymization, and returns the processed frame.\"\"\"\n    detections = face_model.predict(frame, conf=CONFIDENCE_THRESHOLD, verbose=False)\n    \n    for detection in detections:\n        for box in detection.boxes:\n            x1, y1, x2, y2 = map(int, box.xyxy[0])\n            face_region = frame[y1:y2, x1:x2]\n            face_region = cv2.blur(face_region, BLUR_INTENSITY)  # Apply blurring\n            frame[y1:y2, x1:x2] = face_region \n            cvzone.cornerRect(frame, (x1, y1, x2 - x1, y2 - y1), l=9, rt=3)\n\n    return frame\n\ndef process_video(input_video_path, model_path, output_video_path):\n    \"\"\"Processes the video by detecting and anonymizing faces in each frame.\"\"\"\n    cap = cv2.VideoCapture(input_video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    \n    face_model = YOLO(model_path)\n    face_model.overrides['verbose'] = False  # Suppress model logs\n\n    out = initialize_video_writer(output_video_path, FRAME_WIDTH, FRAME_HEIGHT, fps)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break  \n\n        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT)) \n        processed_frame = anonymize_faces(frame, face_model)  \n        out.write(processed_frame)  \n\n    cap.release()\n    out.release()\n    print(f\"Anonymized video saved at {output_video_path}\")\n\nprocess_video(VIDEO_PATH, MODEL_PATH, OUTPUT_VIDEO_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T09:42:53.330565Z","iopub.execute_input":"2024-11-10T09:42:53.330903Z","iopub.status.idle":"2024-11-10T09:42:53.343490Z","shell.execute_reply.started":"2024-11-10T09:42:53.330871Z","shell.execute_reply":"2024-11-10T09:42:53.342622Z"}},"outputs":[],"execution_count":4}]}